{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/P-RAJESWARI/NeuralNetworks/blob/main/Lesson1%3AUsing%20Neural%20Nets%20to%20recognize%20handwritten%20digits/NeuralNetworks_Lesson1_Notebook2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ae0a76",
      "metadata": {
        "id": "a5ae0a76"
      },
      "source": [
        "Sigmoid neurons simulating perceptrons, part II"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83da5a8",
      "metadata": {
        "id": "a83da5a8"
      },
      "source": [
        "Suppose we have the same setup as the last problem - a network of perceptrons. Suppose also that the overall input to the network of perceptrons has been chosen. We won't need the actual input value, we just need the input to have been fixed.\n",
        "\n",
        "1)Suppose the weights and biases are such that w⋅x+b≠0 for the input x to any particular perceptron in the network. Now replace all the perceptrons in the network by sigmoid neurons, and multiply the weights and biases by a positive constant c>0\n",
        "\n",
        "2)Show that in the limit as c→∞ , the behaviour of this network of sigmoid neurons is exactly the same as the network of perceptrons\n",
        "\n",
        "3)How can this fail when w⋅x+b=0 for one of the perceptrons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa2d444",
      "metadata": {
        "id": "4aa2d444"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd05bef",
      "metadata": {
        "id": "efd05bef"
      },
      "source": [
        "Sigmoid Neurons: The sigmoid function is given by:\n",
        "sigma(z)=1/(1+e^-z)\n",
        "where z is given by z=w.x+b\n",
        "x -> Inputs to neuron\n",
        "w -> respective weights of the input\n",
        "b -> bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d339ec",
      "metadata": {
        "id": "52d339ec"
      },
      "outputs": [],
      "source": [
        "#Define sigmoid function with the formula sigma(z)=1/(1+e^-z)\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaedcec1",
      "metadata": {
        "id": "aaedcec1"
      },
      "outputs": [],
      "source": [
        "#To calculate the sigmoid_neuron_output, we need weights,inputs and bias and z=w.x+b should be not equal to zero\n",
        "#Then multiply z with positive constant c>0\n",
        "def sigmoid_neuron_output(inputs,weights,bias,c):\n",
        "    z=c*(np.dot(inputs,weights)+bias)\n",
        "    return sigmoid(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46c1071",
      "metadata": {
        "id": "e46c1071"
      },
      "outputs": [],
      "source": [
        "#Define perceptron function with output 1 if z=w.x+b >=0 and 0 if z=w.x+b < 0\n",
        "def perceptron_output(inputs,weights,bias):\n",
        "    z=np.dot(inputs,weights)+bias\n",
        "    return 1 if z>=0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096f46e4",
      "metadata": {
        "id": "096f46e4"
      },
      "outputs": [],
      "source": [
        "#Define some random input values,their respective weights and bias\n",
        "inputs=np.array([1.0, 2.0, -1.5])\n",
        "weights=np.array([0.5, -0.6, 0.8])\n",
        "bias=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed42cdc",
      "metadata": {
        "id": "2ed42cdc",
        "outputId": "89e15221-8f33-4b5b-b4f3-02385be990d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perceptron output is  0\n"
          ]
        }
      ],
      "source": [
        "#Observe the output of the perceptron\n",
        "perceptron_out=perceptron_output(inputs,weights,bias)\n",
        "print(\"Perceptron output is \",perceptron_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59955f35",
      "metadata": {
        "id": "59955f35",
        "outputId": "82491413-b350-4cb4-8372-8cc68a99e1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sigmoid output with c=1 is 0.14185\n",
            "Sigmoid output with c=10 is 0.00000\n",
            "Sigmoid output with c=100 is 0.00000\n",
            "Sigmoid output with c=1000 is 0.00000\n",
            "Sigmoid output with c=10000 is 0.00000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gomathy\\AppData\\Local\\Temp\\ipykernel_8544\\1844366379.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-z))\n"
          ]
        }
      ],
      "source": [
        "#Sigmoid neuron output with increasing value of c\n",
        "#Observe sigmoid neuron output with increasing value of c\n",
        "for c in [1,10,100,1000,10000]:\n",
        "    sigmoid_out=sigmoid_neuron_output(inputs,weights,bias,c)\n",
        "    print(f\"Sigmoid output with c={c} is {sigmoid_out:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f90dcf",
      "metadata": {
        "id": "03f90dcf"
      },
      "source": [
        "We'll come to the conclusion the behaviour of the sigmoid neuron is same as the perceptron when the value of positive constant c\n",
        "gets increases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1eb3df5",
      "metadata": {
        "id": "e1eb3df5",
        "outputId": "6c4181d9-644c-4f62-f700-e99c88c7f0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sigmoid output as c -> infinity is 0.00000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gomathy\\AppData\\Local\\Temp\\ipykernel_8544\\1844366379.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-z))\n"
          ]
        }
      ],
      "source": [
        "# Check behavior in the limit c -> infinity\n",
        "#The preceptron and the sigmoid neuron behaves same\n",
        "c=1e6\n",
        "sigmoid_out_infinity = sigmoid_neuron_output(inputs,weights,bias, c)\n",
        "print(f\"Sigmoid output as c -> infinity is {sigmoid_out_infinity:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8400b240",
      "metadata": {
        "id": "8400b240"
      },
      "source": [
        "At c -> infinity ,we can come to the conclusion that the sigmoid neuron behaves exactly the same as perceptron for some condition\n",
        "z=w.x+b not equal to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564985a4",
      "metadata": {
        "id": "564985a4"
      },
      "outputs": [],
      "source": [
        "#check the behaviour at z=w.x+b=0\n",
        "#when w.x+b=0,the sigmoid neuron doesn't mimic the behaviour of the perceptron even at c -> infinity\n",
        "failure_inputs=np.array([1.0,-1.0,-1.0])\n",
        "failure_weights=np.array([1.0,0.5,0.5])\n",
        "failure_bias=0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e080f7",
      "metadata": {
        "id": "b4e080f7",
        "outputId": "7a073d68-3e1f-47a2-c2c9-6e441bf76ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure case for c -> infinity output is 0.50000 \n"
          ]
        }
      ],
      "source": [
        "#When w.x+b=0, eventhough c -> infinity ,the behaviour of the sigmoid neuron doesn't mimic the behaviour of perceptron\n",
        "#Since perceptron can output either 0 or 1\n",
        "#But during w.x+b=0,the sigmoid neuron's output will be 0.5\n",
        "sigmoid_failure=sigmoid_neuron_output(failure_inputs,failure_weights,failure_bias,c)\n",
        "print(f\"Failure case for c -> infinity output is {sigmoid_failure:.5f} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a33d891",
      "metadata": {
        "id": "9a33d891",
        "outputId": "3f525a2a-90ec-4d62-e21e-c7338e1d472a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "perceptron_out=perceptron_output(failure_inputs,failure_weights,failure_bias)\n",
        "print(perceptron_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e4eb3f",
      "metadata": {
        "id": "f8e4eb3f"
      },
      "source": [
        "We can also observe the perceptron output at w.x+b=0 ,it is 1 ,since z>=0\n",
        "But sigmoid neuron output is 0.5\n",
        "This is because even though c -> infinity ,when z is 0, multiplying it with c will give us 0\n",
        "Hence 1/(1+e^0)=1/(1+1)=1/2=0.5"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}